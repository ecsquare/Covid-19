{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DMMwithGibsSampling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO2KbLWrG2s/j02mokOryzL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ecsquare/Covid-19/blob/master/DMMwithGibsSampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6plGEeQqwqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "a06563f4-059b-41f8-fc7f-7b21c5aa9d6b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJZIgRC3rC2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "73947a17-1392-4c9d-c84b-a7744ea170b8"
      },
      "source": [
        "cd /content/gdrive/My\\ Drive/Colab\\ Notebooks/vegan_tweets_2020-05-/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/vegan_tweets_2020-05-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXS-QdiorMgH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "f7d52019-10b2-4840-bbfd-8a4243be82b0"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " online_btm.html\t    vegan_2020-05-03.json   vegan_2020-05-06.json\n",
            " vegan_2020-05-01.json\t    vegan_2020-05-04.json  'vegan_2020-05-07 2.json'\n",
            "'vegan_2020-05-02 2.json'   vegan_2020-05-05.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhZrecVFrOnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "data = [json.loads(line)['tweet'] for line in open('vegan_2020-05-01.json', 'r')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJa6z4gLrYBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import re\n",
        "def clean_tweets(text):\n",
        "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
        "    text = re.sub('[0-9]+', '', text)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH8wumzRrd-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [clean_tweets(d) for d in data]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xR0pgM5TZJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('corpus.txt', 'w') as f:\n",
        "    for item in data:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLfTf4imtz8_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b99e0602-795b-4e3e-9bc7-03680c3e3cad"
      },
      "source": [
        "cd /content/gdrive/My\\ Drive/Colab\\ Notebooks/vegan_tweets_2020-05-/"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/vegan_tweets_2020-05-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92I_SvaLuGIt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "c8a36e34-bced-4d3b-ec41-49d9b3fd528b"
      },
      "source": [
        "ls"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " online_btm.html        'vegan_2020-05-02 2.json'   vegan_2020-05-05.json\n",
            " sample_data             vegan_2020-05-03.json      vegan_2020-05-06.json\n",
            " vegan_2020-05-01.json   vegan_2020-05-04.json     'vegan_2020-05-07 2.json'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFzZ426KL6YT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "class GibbsSamplingDMM(object):\n",
        "\t\n",
        "\tnumDocuments = 0\n",
        "\tnumWordsInCorpus = 0\n",
        "\tword2IdVocabulary = {}\n",
        "\tid2WordVocabulary = {}\n",
        "\tdocuments = []\n",
        "\toccurenceToIndexCount = []\n",
        "\ttopicAssignments = []\n",
        "\tdocTopicCount = []\n",
        "\ttopicWordCount = []\n",
        "\tsumTopicWordCount = []\n",
        "\tmultiPros = []\n",
        "\tbetaSum=0.\n",
        "\n",
        "\tdef __init__(self, paramters):\n",
        "\t\tsuper(GibbsSamplingDMM, self).__init__()\n",
        "\t\tself.corpus = paramters[\"corpus\"]\n",
        "\t\tself.output = paramters[\"output\"]\n",
        "\t\tself.ntopics = int(paramters[\"ntopics\"])\n",
        "\t\tself.alpha = float(paramters[\"alpha\"])\n",
        "\t\tself.beta = float(paramters[\"beta\"])\n",
        "\t\tself.niters = int(paramters[\"niters\"])\n",
        "\t\tself.twords = int(paramters[\"twords\"])\n",
        "\t\tself.name = paramters[\"name\"]\n",
        "\n",
        "\tdef analyseCorpus(self):\n",
        "\t\tindexWord=0\n",
        "\t\tdata = open(self.corpus,'r')\n",
        "\t\tfor doc in data:\n",
        "\t\t\tdocument = []\n",
        "\t\t\twordOccurenceToIndexInDocCount = {}\n",
        "\t\t\twordOccurenceToIndexInDoc = []\n",
        "\t\t\tif doc.rstrip!=None:\n",
        "\t\t\t\twords = doc.rstrip().split()\n",
        "\t\t\t\tfor word in words:\n",
        "\n",
        "\t\t\t\t\tif word in self.word2IdVocabulary:\n",
        "\t\t\t\t\t\tdocument.append(self.word2IdVocabulary[word])\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tself.word2IdVocabulary[word]=indexWord\n",
        "\t\t\t\t\t\tself.id2WordVocabulary[indexWord]=word\n",
        "\t\t\t\t\t\tdocument.append(indexWord)\n",
        "\t\t\t\t\t\tindexWord+=1\n",
        "\n",
        "\t\t\t\t\tif word in wordOccurenceToIndexInDocCount:\n",
        "\t\t\t\t\t\twordOccurenceToIndexInDocCount[word]+=1\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\twordOccurenceToIndexInDocCount[word]=1\n",
        "\n",
        "\t\t\t\t\twordOccurenceToIndexInDoc.append(wordOccurenceToIndexInDocCount[word])\n",
        "\n",
        "\t\t\t\tself.numWordsInCorpus+=len(document)\n",
        "\t\t\t\tself.numDocuments+=1\n",
        "\t\t\t\tself.documents.append(document)\n",
        "\t\t\t\tself.occurenceToIndexCount.append(wordOccurenceToIndexInDoc)\n",
        "\n",
        "\t\tself.betaSum=len(self.word2IdVocabulary)*self.beta\n",
        "\n",
        "\n",
        "\tdef topicAssigmentInitialise(self):\n",
        "\t\tself.docTopicCount = [0 for x in range(self.ntopics)]\n",
        "\t\tself.sumTopicWordCount = [0 for x in range(self.ntopics)]\n",
        "\n",
        "\t\tfor i in range(self.ntopics):\n",
        "\t\t\t\tself.topicWordCount.append([0 for x in range(len(self.word2IdVocabulary))])\n",
        "\n",
        "\t\tfor i in range (self.numDocuments):\n",
        "\t\t\ttopic = random.randint(0,self.ntopics-1)\n",
        "\t\t\tself.docTopicCount[topic]+=1\n",
        "\t\t\t\n",
        "\t\t\tfor j in range (len(self.documents[i])):\n",
        "\t\t\t\tself.topicWordCount[topic][self.documents[i][j]]+=1\n",
        "\t\t\t\tself.sumTopicWordCount[topic]+=1\n",
        "\n",
        "\t\t\tself.topicAssignments.append(topic)\n",
        "\n",
        "\tdef nextDiscrete(self,a):\n",
        "\t\tb = 0.\n",
        "\n",
        "\t\tfor i in range(len(a)):\n",
        "\t\t\tb+=a[i]\n",
        "\n",
        "\t\tr = random.uniform(0.,1.)*b\n",
        "\t\t\n",
        "\t\tb=0.\n",
        "\t\tfor i in range (len(a)):\n",
        "\t\t\tb+=a[i]\n",
        "\t\t\tif(b>r):\n",
        "\t\t\t\treturn i\n",
        "\t\treturn len(a)-1\n",
        "\n",
        "\tdef sampleInSingleIteration(self,x):\n",
        "\t\tprint (\"iteration: \"+str(x))\n",
        "\t\tfor d in range(self.numDocuments):\n",
        "\t\t\ttopic = self.topicAssignments[d]\n",
        "\t\t\tself.docTopicCount[topic]-=1\n",
        "\t\t\tdocSize = len(self.documents[d])\n",
        "\t\t\tdocument = self.documents[d]\n",
        "\n",
        "\t\t\tfor w in range(docSize):\n",
        "\t\t\t\tword = document[w]\n",
        "\t\t\t\tself.topicWordCount[topic][word]-=1\n",
        "\t\t\t\tself.sumTopicWordCount[topic]-=1\n",
        "\t\t\t\n",
        "\n",
        "\t\t\tfor t in range(self.ntopics):\n",
        "\t\t\t\tself.multiPros[t] = self.docTopicCount[t]+self.alpha\n",
        "\n",
        "\t\t\t\tfor w in range(docSize):\n",
        "\t\t\t\t\tword = document[w]\n",
        "\t\t\t\t\tself.multiPros[t] *= (self.topicWordCount[t][word]+self.beta+self.occurenceToIndexCount[d][w]-1)/(self.sumTopicWordCount[t]+w+self.betaSum)\n",
        "\t\t\t\t\n",
        "\t\t\t\t\t\n",
        "\t\t\t#print self.multiPros\n",
        "\t\t\ttopic = self.nextDiscrete(self.multiPros)\n",
        "\t\t\t#print topic\n",
        "\n",
        "\t\t\tself.docTopicCount[topic]+=1\n",
        "\n",
        "\t\t\tfor w in range(docSize):\n",
        "\t\t\t\tword = document[w]\n",
        "\t\t\t\tself.topicWordCount[topic][word]+=1\n",
        "\t\t\t\tself.sumTopicWordCount[topic]+=1\n",
        "\n",
        "\t\t\tself.topicAssignments[d] = topic\n",
        "\n",
        "\tdef inference(self):\n",
        "\t\tself.multiPros = [0 for x in range(self.ntopics)]\n",
        "\t\t[self.sampleInSingleIteration(x) for x in range(self.niters)]\n",
        "\n",
        "\tdef writeTopicAssignments(self):\n",
        "\t\tfile = open(self.output+self.name+\".topicAssignments\",\"w\")\n",
        "\t\t#for i in range(self.numDocuments):\n",
        "\t\t[file.write(str(self.topicAssignments[i])+\"\\n\") for i in range(self.numDocuments)]\n",
        "\n",
        "\n",
        "\n",
        "\tdef writeTopTopicalWords(self):\n",
        "\t\tfile = open(self.output+self.name+\".topWords\",\"w\") \n",
        "\t\tfor t in range(self.ntopics):\n",
        "\t\t\twordCount = {w:self.topicWordCount[t][w] for w in range(len(self.word2IdVocabulary))}\n",
        "\t\t\t\n",
        "\t\t\tcount =0\n",
        "\t\t\tstring=\"Topic \"+str(t)+\": \"\n",
        "\t\t\t\n",
        "\t\t\tfor index in sorted(wordCount, key=wordCount.get, reverse=True):\n",
        "\t\t\t\tstring += self.id2WordVocabulary[index]+\" \"\n",
        "\t\t\t\tcount+=1\n",
        "\t\t\t\tif count>=self.twords:\n",
        "\t\t\t\t\tfile.write(string+\"\\n\") \n",
        "\t\t\t\t\t# print string\n",
        "\t\t\t\t\tbreak\n",
        "\t\tfile.close()\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii_4I3r3uOp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hparams = {\"corpus\":\"corpus\", \n",
        "          \"output\": \"output\", \n",
        "          \"ntopics\": \"20\", \n",
        "          \"alpha\":\"0.1\",\n",
        "          \"beta\":\"0.1\", \n",
        "          \"niters\":\"200\",\n",
        "          \"twords\":\"20\",\n",
        "          \"name\":\"model\"}\n",
        "\n",
        "model = GibbsSamplingDMM(params)\n",
        "model.analyseCorpus()\n",
        "model.topicAssigmentInitialise()\n",
        "model.inference()\n",
        "\t\n",
        "print (\"Writing Results\")\n",
        "model.writeTopTopicalWords()\n",
        "model.writeTopicAssignments()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye-E3IDgTfia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}